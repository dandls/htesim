\documentclass[nojss]{jss}

%% packages
\usepackage{amstext}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{thumbpdf}
\usepackage{rotating}
%% need no \usepackage{Sweave}

%% additional commands
\newcommand{\squote}[1]{`{#1}'}
\newcommand{\dquote}[1]{``{#1}''}
\newcommand{\fct}[1]{\texttt{#1()}}
\newcommand{\class}[1]{\squote{\texttt{#1}}}

%% random vars
\def \xvec {\text{\boldmath$x$}}
\def \mX {\text{\boldmath$X$}}
\def \yvec {\text{\boldmath$y$}}
\def \mY {\text{\boldmath$Y$}}
\def \zvec {\text{\boldmath$z$}}
\def \mZ {\text{\boldmath$Z$}}
\newcommand{\rZ}{Z}
\newcommand{\rY}{Y}
\newcommand{\rX}{\mX}
\newcommand{\rz}{z}
\newcommand{\ry}{y}
\newcommand{\rx}{\xvec}
\newcommand{\ru}{\uvec}
\newcommand{\erx}{x}
\newcommand{\Xspace}{\mathcal{X}}
\DeclareMathOperator{\ND}{N}

%% for internal use
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}
\newcommand{\readme}[1]{\emph{\marginpar{README} (#1)}}

\hyphenation{Qua-dra-tic}

\title{\pkg{htesim}: A Simulation Study Framework for Heterogeneous Treatment Effect Estimation}
\Plaintitle{htesim: A Simulation Study Framework for Heterogeneous Treatment Effect Estimation}

\author{Susanne Dandl\\Ludwig-Maximilians-Universit\"at M\"unchen
\And Torsten Hothorn\\University of Z\"urich}
\Plainauthor{Susanne Dandl, Torsten Hothorn}

\Abstract{
The \pkg{htestim} package provides an extensive simulation study framework to
evaluate methods to estimate heterogeneous treatment effects.
}
\Keywords{heterogeneous treatment effect estimation, simulation study, randomized and observational data}

\Address{
Susanne Dandl \\
Department of Statistics \\
Chair of Statistical Learning and Data Science \\
LMU Munich\\
E-mail: \email{Susanne.Dandl@stat.uni-muenchen.de} \\
URL: \url{https://www.slds.stat.uni-muenchen.de/people/dandl/} \\

Torsten Hothorn\\
Institut f\"ur Epidemiologie, Biostatistik und Pr\"avention \\
Universit\"at Z\"urich \\
Hirschengraben 84\\
CH-8001 Z\"urich, Switzerland \\
E-mail: \email{Torsten.Hothorn@R-project.org}\\
URL: \url{http://user.math.uzh.ch/hothorn/}
}


\begin{document}

<<include=FALSE>>=
library("knitr")
opts_chunk$set(
  tidy=FALSE, eval = TRUE
)
@

<<setup, echo = FALSE, results='hide'>>=
suppressWarnings(RNGversion("3.5.2"))
options(width = 70)
@

\section{Introduction} \label{sec:intro}
Estimation of heterogeneous treatment effects from randomized or observational data
received a lot of attention over the last years, especially in medical sciences.
Methods to identify subgroups with homogeneous
treatment effects or to derive personalized treatment effects are various and
range from deploying classical lasso regression \citep{Qian_Murphy_2011, Tian_Alizadeh_Gentles_Tibshirani_2014}, over recursive partitioning \citep{Athey_Tibshirani_Wager_2019, Seibold_Zeileis_Hothorn_2017} to
deep neural networks \citep{Shalit_Johansson_Sontag_2017, Yoon_Jordon_Schaar_2018}.
Since these methods do not perform equally good in different settings (e.g., observational
vs. randomized data, low vs. high dimensional data, constant vs. complex treatment effects, etc.),
extensive simulation studies are necessary to compare these methods empirically.
The \pkg{htesim} \proglang{R} package provides a framework to easily set up simulation studies
that could differ in their
\begin{itemize}
\item treatment, prognostic or propensity score functions
\item distribution functions of outcomes
\item distribution functions of covariates
\item number of observations
\item number of explanatory variables
\end{itemize}
With this toolkit, it is easy to define various data generating processes (\code{dgp}) and to sample
study observations with known ground truth treatment effects from them (\code{simulate.dpg}).
Users could define their own treatment, prognostic and propensity score functions,
or they make use of multiple predefined functions (\code{tF, mF, pF}).
These predefined functions are based on \cite{Wager_Athey_2018}, \cite{Athey_Tibshirani_Wager_2019} and \cite{Nie_Wager_2020}.
They were also employed by \cite{Dandl_Hothorn_Seibold_2021} to compare multiple forest-based methods.
A dedicated dataset of the study settings and performances of these methods  is part of this package (\code{data("dandl")})
so that others could reproduce this study and compare the performance of their methods with them.

\proglang{R} offers a few packages that are tailored to causal treatment effect estimation. Many of them generate data based on
structural equation models (packages \pkg{simcausal} \citep{Sofrygin_Laan_Neugebauer_2017}, \pkg{lavaan} \citep{Rosseel_2012} and \pkg{simsem} \citep{Pornprasertmanit_Miller_Schoemann_2020}) but not parametric distribution functions like \pkg{htesim}.
Other packages only cover special cases like generalized multistate models or survival models
(packages \pkg{survsim} \citep{Morina_Navarro_2014}, \pkg{gems} \citep{Blaser_Salazar_Estill_2015}).

The package \pkg{causalToolbox} provides the most similar functionalities to
\pkg{htesim}. It mainly focuses on estimation methods, but also includes a function
to conduct experiments. It offers predefined underlying effect functions but
no flexibility to use own functions like \pkg{htesim}. Furthermore, it only covers normally distributed outcomes and no other distributions.

Overall, the distinguishing features of \pkg{htesim} are that
\begin{enumerate}
\item[(1)] simulation data are based on parametric distribution functions
that cover simple scenarios like normally distributed outcomes or covariates but
also more complex scenarios like Weibull-distributed outcomes to imitate survival data.
\item[(2)] it gives the user the flexibility to define own effect functions.
\item[(3)] it provides the necessary functionality to replicate the study of
\cite{Dandl_Hothorn_Seibold_2021}.
\end{enumerate}

In the upcoming section, the most important functions of \pkg{htesim} are presented
followed by some examples on how to employ own effect functions and how to
replicate the study framework of \cite{Dandl_Hothorn_Seibold_2021}.

\section{Basic Usage} \label{sec:functions}

\subsection{Overview} \label{subsec:overview}
To simulate a data set for empirical performance evaluation, three functions are
necessary: \code{dgp} to define a manual for data generation, \code{simulate.dgp} to simulate training and test data from the manual, and \code{predict.dgp} to receive the ground truth treatment effect, prognostic effect and propensity score.

In the following, we give details on these functions accompanied by an illustrative example that replicates the first experiment of \cite{Wager_Athey_2018}.

<<setup2>>=
library("htesim")
library("checkmate")
set.seed(8008)
@

\subsection{Define a Data Generating Process} \label{subsec:dgp}
\code{dpg} defines a manual for the data generating process.
The underlying propensity score function \code{p}, the prognostic effect function \code{m} (also called
conditional mean) and treatment effect function \code{t} must be passed to this function.
\code{dpg} allows as inputs functions, character names of functions or
constant values.

Furthermore, the underlying model for the outcome (\code{model}) and covariates
(\code{xmodel}) need to be specified.
Currently, a normal linear regression model, a binary logistic regression model,
a Weibull model and a 4-nomial model for the outcome are supported.
The covariates could be either normally or uniformly distributed.
If they are normally distributed, the user could specify a function for the standard deviation (\code{sd}).
Furthermore, a proportion \code{ol} $\in \mathbb{R}$ of the treatment effect could be added to the prognostic effect.

As an example, we have a look at the first data generating process of the simulation
study of \cite{Wager_Athey_2018}.
The propensity score function is  $\pi(\rx) = \frac{1}{4}(1 + \beta_{2, 4}(x_1))$,
the prognostic effect function is $\mu(\rx) = 2x_1 - 1$ and there is no
treatment effect $t(\rx) \equiv 0$.
Outcomes $Y$ are sampled from the conditional distribution
$$ (Y|\rX = \rx) \sim N(\mu(\rx) + \tau(\rx)W, 1)$$
with $W$ as the treatment indicator and $(W | \rX = \rx) \sim B(1, \pi(\rx))$.
Covariates $\rX$ are sampled from a uniform distribution
$(\rX \sim U([0, 1]^P))$ with $P = \{2, 5, 10, 15, 20, 30\}$.

All propensity score functions, prognostic effect functions and treatment effect functions of \cite{Wager_Athey_2018}, \cite{Athey_Tibshirani_Wager_2019} and \cite{Nie_Wager_2020} are already implemented in \pkg{htesim}.
Please consult the documentation of \code{pF}, \code{mF} and \code{tF}
for an overview and in-depth definition of these functions.
The propensity score function of our example is implemented in \code{pF_x1}
 and the prognostic effect function in \code{mF_x1}.

The following code generates the manual to replicate the study setting.
<<ex:dgp>>=
dgp1 <- dgp(p = pF_x1, m = mF_x1, t = 0, ol = 0, model = "normal",
  xmodel = "unif")
@

The returned object is a list of class \code{dgp} with the following entries.
<<ex2:dgp2>>=
dgp1
class(dgp1)
@

\subsection{Simulate from Data Generating Process} \label{subsec:simulate}
The S3 method \code{simulate.dgp} simulates data given a \code{dgp} object,
the number of observations \code{nsim} and number of predictors \code{dim}.
Optionally, users can generate a test dataset by specifying the number of
test observations in \code{nsimtest}.
An optional \code{seed} helps to reproduce a study dataset in prospective runs.

In the above example, the authors sampled \code{nsim = 500} observations for training
and \code{nsimtest = 1000} observations for evaluation.
The number of predictors varied between $2$ and $30$.
For illustration, we chose \code{dim = 2}.

<<ex:sim>>=
sim1 <- simulate(object = dgp1, nsim = 500L, d = 2L, nsimtest = 1000L)
head(sim1)
nrow(sim1)
@
In addition to our uniformly distributed covariates \code{X1} and \code{X2},
a normally distributed outcome \code{y} was sampled as well as the treatment indicator
\code{trt} based on our defined effect and propensity score functions.

The test dataset can be accessed via
<<ex:simtest>>=
testdf <- attr(sim1, "testxdf")
head(testdf)
@
It consists of covariates (the number is equal to \code{dim})
and the treatment indicator which is also sampled from a binomial distribution
with probability $\pi(\rx)$.

\subsection{Compute Ground Truth for New Data} \label{subsec:predict}
To evaluate if a method accurately estimates the treatment effect or potentially (but less common) the prognostic effect, propensity scores or standard deviation we need the ground true effects or scores for the test dataset.
For this purpose the S3 method \code{predict.dgp} exists. It needs as an input the \code{dgp object} generated by \code{dgp} and the new data frame.
Continuing with the above example, we get the ground truth by calling
<<ex:pred>>=
predtest <- predict(object = dgp1, newdata = testdf)
head(predtest)
@
\code{pfct} corresponds to the propensity score, \code{mfct} to the
conditional mean or prognostic effect, \code{tfct} to the treatment effect and
\code{sdfct} to the standard deviation of the conditional distribution of $(Y|\rX = \rx)$

\section{Advanced Usage}
\pkg{htesim} also offers the flexibility for users to specify and simulate from their own functions and provides the necessary functionality to replicate previous studies.
This is demonstrated in this chapter.
For the former, we use a self-chosen example and for the latter, we replicate the first study setting of \cite{Dandl_Hothorn_Seibold_2021}.


\subsection{Use your own Functions} \label{subsec:ownfunc}
In Section~\ref{sec:functions} we saw that \code{simulate.dgp} generates a dataset of
covariates by drawing random numbers from a uniform  or normal distribution.
These variables are labelled as \code{X1}, \code{X2}, and so on.
A dataset with these variables is the input for a new function.
As an example, we want our treatment effect function to have the form
$$ \tau(\rx) = (x_1 + x_2)^2/4 $$
with $\nu \ge 0$, our prognostic effect function should be
$$ \mu(\rx) = exp(x_1 + 0.3 x_2 + 0.4 x_3).$$
The propensity score should be $0.5$ for all observations, meaning that
we conduct a randomized trial.
We can setup our functions with
<<owntE>>=
tE_nu_x1_x2 <- function(x) {
  return(((x[, "X1"] + x[, "X2"])^2)/4)
}

mE_exp_x1_x3 <- function(x) {
  return(exp(x[, "X1"] + 0.3 * x[, "X2"] + 0.4 * x[, "X3"]))
}
@
To receive simulation study data we pass these functions to \code{dgp}. All other arguments were
set to their defaults (normally distributed outcomes and uniformly distributed covariates).

<<dgpowntE>>=
dgpown <- dgp(p = 0.5, m = mE_exp_x1_x3, t = tE_nu_x1_x2)
@

To simulate 500 observations with $5$ predictors from this \code{dgp} we could simply call
<<simowntE>>=
simown <- simulate(dgpown, nsim = 500, dim = 5)
head(simown)
@

\subsection{Replicate Study Setting of Dandl et al. (2021)} \label{subsec:dandl}
We want to motivate readers to compare the results of their methods to the methods investigated in
\cite{Dandl_Hothorn_Seibold_2021}.
Therefore, the study setting and the corresponding results of the forest approaches are available in
\pkg{htesim}.

<<loadres>>=
load(system.file("extdata/dandl.rda", package = "htesim"))
head(dandl)
@

The column \code{setup} corresponds to the unique data generating process defined  by \code{p}, \code{m}, \code{t}, \code{sd}, \code{ol}, \code{model}, \code{xmodel}, \code{nsim} and \code{dim}.
Each data generating process was repeated 100 times. \code{repl} stores the rerun ids.
Columns \code{p}, \code{m}, \code{t}, \code{sd}, \code{ol}, \code{model} and \code{xmodel}
comprise arguments for \code{dgp}, while \code{nsim}, \code{dim}, \code{nsimtest} and \code{seed}
should be inserted into \code{simulate.dgp}.

The information in this dataset is enough to replicate the study data.
For illustration, we will generate a study dataset derived from the first
row of \code{res}.

<<row1>>=
study1 <- dandl[1,]
@

Since the column names of \code{study1} matches the arguments of \code{dgp} and \code{simulate},
we can use \code{do.call} to generate the simulated data set.
The \code{seed} helps us to receive the exact and not approximate study data set of \cite{Dandl_Hothorn_Seibold_2021}.

<<getdata>>=
dgp1 <- do.call(dgp,
  as.list(study1)[c("p", "m", "t", "sd", "ol", "model", "xmodel")])
# equivalent to
dgp1 <- dgp(p = study1$p, m = study1$m, t = study1$t, sd = study1$sd,
  ol = study1$ol, model = study1$model, xmodel = study1$xmodel)

sim1 <- do.call(simulate, c(list(object = dgp1),
  as.list(study1)[c("nsim", "dim", "seed", "nsimtest")]))
# equivalent to
sim1 <- simulate(dgp1, nsim = study1$nsim, dim = study1$dim,
  seed = study1$seed, nsimtest = study1$nsimtest)

head(sim1)
@

The test data was attached to \code{sim1} as an attribute.

<<gettest>>=
testdf <- attr(sim1, "testxdf")
head(testdf)
@

We receive the true effects for the test data using
<<predtest>>=
tau <- predict(dgp1, newdata = testdf)[, "tfct"]
head(tau)
@

\cite{Dandl_Hothorn_Seibold_2021} compared different forest-based methods to estimate treatment effects.
Performances of these methods were assessed by mean squared error
$$\frac{1}{1000} \sum_{i = 1}^{1000}(\tau(\rx_i) - \hat{\tau}(\rx_i))$$
evaluated on the test sample.
The results for each method are also part of the given data frame \code{dandl}.

<<algonams>>=
# Method names
methodnams <- c("mob", "hybrid", "equalized",  "cf", "mobcf",
  "mobhonest", "hybridhonest", "equalizedhonest", "cfhonest", "mobcfhonest")
# Get results
study1[, methodnams]
@

Given the replicated study data, users could evaluate new methods against
the forest-based methods.
As an example, we compare the performances against a linear model with one interactions term.
<<newmeth>>=
mod <- lm(y ~ trt + trt:X3, data = sim1)
test0 <- test1 <- testdf
test0$trt <- "0"
test1$trt <- "1"
tauhat <- predict(mod, test1) - predict(mod, test0)
head(tauhat)
@

The performance is evaluated by the MSE

<<newmethmse>>=
mean((tau - tauhat)^2)
@

We can apply the linear interaction model to each of 9600 simulation settings specified in \code{dandl}.
The following helper function creates a study dataset from a study setting,
fits the interaction model on it, estimates the treatment effect and
returns the MSE.
The function is applied to each row of \code{dandl} and the results get
attached to it.

<<study>>=
run_linmod <- function(i) {
  # Extract row
  row <- dandl[i,]
  # define dgp
  dgp1 <- do.call(dgp,
  as.list(row)[c("p", "m", "t", "sd", "ol", "model", "xmodel")])
  # simulate train and test data
  sim1 <- do.call(simulate, c(list(object = dgp1),
    as.list(row)[c("nsim", "dim", "seed", "nsimtest")]))
  testdf <- attr(sim1, "testxdf")
  # get true tau
  tau <- predict(dgp1, newdata = testdf)[, "tfct"]
  # fit linear model with one interaction term
  mod <- lm(y ~ trt + trt:X3, data = sim1)
  # get estimated treatment effect
  test0 <- test1 <- testdf
  test0$trt <- "0"
  test1$trt <- "1"
  tauhat <- predict(mod, test1) - predict(mod, test0)
  # evaluation
  mse <- mean((tau - tauhat)^2)
  return(mse)
}
mse <- sapply(1:nrow(dandl), FUN = run_linmod)

# add results to dandl
dandl$linmod <- mse

# add name to vector of method names
methodnams <- c(methodnams, "linmod")
@

With the \proglang{R} package \pkg{latttice} we compare the performance of the forest-based methods and the linear model visually.
Therefore, we need to reshape the data from a wide to long format.

<<reshape>>=
res <- reshape(dandl, direction = "long", varying = methodnams, idvar = c("p",
  "m", "t", "sd", "ol", "model", "xmodel", "nsim", "dim", "nsimtest", "seed"),
  v.names = "value", timevar = "algorithm")
rownames(res) <- NULL # reset rownames
res$algorithm <- methodnams[res$algorithm]
head(res)
@
Each row corresponds to the results of \textit{one} method, for \textit{one} study setting (unique data generating process, number of training observations and dimensions) and \textit{one} replication.
Each row of our plot should correspond to one data generating process (i.e., \code{setup}) and each row to one unique combination of \code{nsim} and \code{dim}.
The following function refactors our dataset to a suitable format by generating
the necessary information.

<<settings>>=
refactor <- function(df, method.nams) {
  plev <- c("pF_x1", "pF_x3", "pF_x4", "pF_eta_x1_x2", "0.5", "pF_x2_x3",
    "pF_exp_x1_x2")
  mlev <- c("0", "mF_x1", "mF_x3", "mF_sin_x1_x5", "mF_max_x1_x5",
    "mF_log_x1_x3", "mF_max2_x1_x5")
  tlev <- c("0", "tF_exp", "tF_div", "tF_log", "1", "tF_max")
  nlev <- c(800, 1600)
  dlev <- c(10, 20)

  df$p <- factor(df$p, labels = plev, levels = plev)
  df$m <- factor(df$m, labels = mlev, levels = mlev)
  df$t <- factor(df$t, labels = tlev, levels = tlev)
  df$nsim <- factor(df$nsim, labels = nlev, levels = nlev)
  levels(df$nsim) <- paste("N = ", levels(df$nsim))
  df$dim <- factor(df$dim, labels = dlev, levels = dlev)
  levels(df$dim) <- paste("P = ", levels(df$dim))

  df$nd <- with(df, interaction(dim, nsim, sep = ", "))
  lev <- levels(df$nd)
  levels(df$nd) <- sapply(strsplit(lev, ", "),
    function(x) paste(x[2], ", ", x[1]))
  df$setup <- factor(df$setup)

  df <- df[, c("algorithm", "setup", "repl", "nd", "ol", "seed", "value")]

  df$algorithm <- factor(as.character(df$algorithm), levels = method.nams,
    labels = gsub("honest", "-honest", method.nams))
  df <- df[!is.na(df$algorithm),]
  names(df)[names(df) == "result.res"] <- "value"
  return(df)
}
@

This function is applied to our dataset.

<<change>>=
res <- refactor(res, method.nams =  methodnams)
head(res)
@
The column \code{nd} defines the rows in the plot and the column
\code{setup} the columns.

Next, we set up the plots with \pkg{lattice}.
We change the names of the hybrid and equalized approach according to \cite{Dandl_Hothorn_Seibold_2021}:
\begin{itemize}
  \item hybrid: $\text{mob}(\hat{W})$
  \item equalized: $\text{mob}(\hat{W}, \hat{Y})$
\end{itemize}

<<<hybeq>>=
lookup <- c(
  "mob" = "mob",
  "hybrid" = expression("mob"(widehat(W))),
  "equalized" = expression("mob"(widehat(W), widehat(Y))),
  "mobcf" = "mobcf",
  "cf" = "cf",
  "mob-honest" = "h-mob",
  "hybrid-honest" = expression("h-mob"(widehat(W))),
  "equalized-honest" = expression("h-mob"(widehat(W), widehat(Y))),
  "mobcf-honest" = "h-mobcf",
  "cf-honest" = "h-cf",
  "linmod" = "linmod"
)
@

Each method will have an own colour coding.
<<color>>=
cols <- c("mob" = "snow", "mob-honest" = "snow4",
  "hybrid" = "tan",  "hybrid-honest" = "tan4",
  "equalized" = "darkorchid1", "equalized-honest" = "darkorchid4",
  "cf" = "deepskyblue", "cf-honest" = "deepskyblue4",
  "mobcf" = "darkolivegreen1", "mobcf-honest" = "darkolivegreen4",
  "linmod" = "darkorange")
colornams <- lookup[names(cols)]
@

This colour coding is needed for further plotting options.
<<lattice>>=
library("lattice")
library("latticeExtra")

# Lattice options and plot appearance
trellis.par.set(list(plot.symbol = list(col="black",pch=18, cex=0.75),
  box.rectangle = list(col=1),
  box.umbrella = list(lty=1, col=1),
  strip.background = list(col = "white")))
ltheme <- canonical.theme(color = FALSE)     # black and white theme
ltheme$strip.background$col <- "transparent" # change strip background
lattice.options(default.theme = ltheme)

# Setup rows and columns of plot
sc <- function(which.given, ..., factor.levels) {
  if (which.given == 2) {
    strip.default(which.given = which.given, ..., factor.levels)
  } else {
    strip.default(which.given = 1, ...,
      factor.levels)
  }
}

# Fill each entry with boxplots
mypanel <- function(x, y, groups, subscripts, ...) {
  fill <- cols[intersect(levels(x), unique(x))]
  panel.bwplot(x = x, y = y, fill = fill, ...)
  tapply(1:length(y), groups[subscripts], function(i) {
    xi <- 1:nlevels(x)
    yi <- y[i][match(xi, unclass(x[i]))]
    llines(x = xi, y = yi,
      col = rgb(0.1, 0.1, 0.1, 0.03))
  })
}

# set up legend at top of plots
mykey <- list(space="top", rectangles=list(col=cols),
  text=list(colornams), columns = ceiling(length(methodnams)/2))

# label of y-axis, MSE
ylab <- expression(paste(frac(1, 1000), "",
  sum((tau(x[i]) - hat(tau)(x[i]))^2, i == 1, 1000)))

# plotting function
plot_results <- function(pltdata, sc, ylim) {
  plt <- bwplot(value ~ algorithm | setup + nd, data = pltdata,
    ylab = list(ylab), ylim = ylim,
    groups = repl, panel = mypanel,
    as.table = TRUE, strip = sc, key = mykey,
    scales = list(relation = "same", x = list(rot = 60, labels = lookup)))
  useOuterStrips(plt, strip = sc)
}
@

Since there is not enough space to show the results of all setups in one plot,
we follow \cite{Dandl_Hothorn_Seibold_2021} and distinguish between
the following settings:

\begin{itemize}
\item Settings introduced by \cite{Wager_Athey_2018} and \cite{Athey_Tibshirani_Wager_2019}
\begin{itemize}
\item without overlay meaning \code{ol} is equal to 0: setups 1 to 8
<<set1>>=
subset1 <- subset(res, setup %in% 1:16 & ol == 0)
@
\item with overlay meaning \code{ol} is equal to 0.5: setups 9 to 16
<<set2>>=
subset2 <- subset(res, setup %in% 1:16 & ol == 0.5)
@
\end{itemize}
\item Settings introduced by \cite{Nie_Wager_2020}
\begin{itemize}
\item without overlay meaning \code{ol} is equal to 0: setups 17 to 20
<<set3>>=
subset3 <- subset(res, setup %in% 17:24 & ol == 0)
@
\item with overlay meaning \code{ol} is equal to 0.5: setups 21 to 24
<<set4>>=
subset4 <- subset(res, setup %in% 17:24 & ol == 0.5)
@
\end{itemize}
\end{itemize}
If \code{ol} is 0.5, half of the treatment effect is added to the
prognostic effect.
Finally we can plot the results
\newpage
<<plot, fig.width=10, fig.height = 10.5, fig.width = 13>>=
plot_results(subset1, sc = sc)
@
\newpage
<<plot2, fig.width=10, fig.height = 10.5, fig.width = 13>>=
plot_results(subset2, sc = sc)
@
\newpage
<<plot3, fig.width=10, fig.height = 10.5, fig.width = 13>>=
plot_results(subset3, sc = sc)
@
\newpage
<<plot4, fig.width=10, fig.height = 10.5, fig.width = 13>>=
plot_results(subset4, sc = sc)
@

If users want to visualize the result of another method, they need to attach the MSEs of their method to \code{dandl} and need to adjust the vector of method names \code{methodnams} and their color coding \code{cols}.
All other chunks of this section should work without any adjustments.

\section{Summary} \label{summary}
This vignette introduced the package \pkg{htesim} that provides an extensive simulation study framework to evaluate methods to estimate heterogeneous treatment effects.
It illustrated how to generate a simulation dataset from predefined functions for prognostic and predictive effects and propensity scores to put methods for treatment effects to the proof.
Furthermore, it explained how users can integrate their own functions.
The vignette also provided the necessary functions to reproduce the study framework of \cite{Dandl_Hothorn_Seibold_2021}.
It also gave guidance on how to compare the results of a new method visually against the forest-based methods evaluated by \cite{Dandl_Hothorn_Seibold_2021}.
We hope that all these examples remove hurdles to use \pkg{htesim} for prospective studies to evaluate methods for heterogeneous treatment effects.

\newpage

\bibliography{literature}

\end{document}
